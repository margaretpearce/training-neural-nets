{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing out techniques from:\n",
    "# http://neuralnetworksanddeeplearning.com/chap3.html#how_to_choose_a_neural_network's_hyper-parameters\n",
    "\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.500000</td>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.445368</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.250000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75.500000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112.750000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
       "count  150.000000    150.000000   150.000000    150.000000   150.000000\n",
       "mean    75.500000      5.843333     3.057333      3.758000     1.199333\n",
       "std     43.445368      0.828066     0.435866      1.765298     0.762238\n",
       "min      1.000000      4.300000     2.000000      1.000000     0.100000\n",
       "25%     38.250000      5.100000     2.800000      1.600000     0.300000\n",
       "50%     75.500000      5.800000     3.000000      4.350000     1.300000\n",
       "75%    112.750000      6.400000     3.300000      5.100000     1.800000\n",
       "max    150.000000      7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the iris data set\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"label_num\"] = pd.factorize(data[\"Species\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                int64\n",
       "Sepal.Length    float64\n",
       "Sepal.Width     float64\n",
       "Petal.Length    float64\n",
       "Petal.Width     float64\n",
       "Species          object\n",
       "label_num         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width     Species  \\\n",
       "131  132           7.9          3.8           6.4          2.0   virginica   \n",
       "121  122           5.6          2.8           4.9          2.0   virginica   \n",
       "96    97           5.7          2.9           4.2          1.3  versicolor   \n",
       "65    66           6.7          3.1           4.4          1.4  versicolor   \n",
       "26    27           5.0          3.4           1.6          0.4      setosa   \n",
       "69    70           5.6          2.5           3.9          1.1  versicolor   \n",
       "119  120           6.0          2.2           5.0          1.5   virginica   \n",
       "90    91           5.5          2.6           4.4          1.2  versicolor   \n",
       "13    14           4.3          3.0           1.1          0.1      setosa   \n",
       "33    34           5.5          4.2           1.4          0.2      setosa   \n",
       "\n",
       "     label_num  \n",
       "131          2  \n",
       "121          2  \n",
       "96           1  \n",
       "65           1  \n",
       "26           0  \n",
       "69           1  \n",
       "119          2  \n",
       "90           1  \n",
       "13           0  \n",
       "33           0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_numeric = data.drop([\"ID\", \"Species\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "data_array = data_numeric.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into train, validation, and test\n",
    "x = data_array[:,:-1]\n",
    "y = data_array[:,-1:]\n",
    "\n",
    "x_trainval, x_test, y_trainval, y_test = train_test_split(x, y, test_size=0.1, train_size=0.9)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=.10, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 4.8,  3.1,  1.6,  0.2]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 2.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networking Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.3763 - acc: 0.3223     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.2932 - acc: 0.2727     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.2515 - acc: 0.2562     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 1.2351 - acc: 0.3471     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 1.2217 - acc: 0.3554     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 1.2112 - acc: 0.3554     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 1.2038 - acc: 0.3554     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 1.1871 - acc: 0.3554     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 1.1708 - acc: 0.3388     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 1.1643 - acc: 0.3554     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 1.1514 - acc: 0.3388     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 1.1430 - acc: 0.2479     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 1.1336 - acc: 0.2479     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 1.1246 - acc: 0.2314     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 1.1196 - acc: 0.1405     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 1.1126 - acc: 0.1653     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 1.1076 - acc: 0.2231     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 1.0997 - acc: 0.2314     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 1.0954 - acc: 0.3306     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 1.0912 - acc: 0.2231     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 1.0869 - acc: 0.1322     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 1.0835 - acc: 0.1322     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 1.0804 - acc: 0.1157     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 1.0752 - acc: 0.1405     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 1.0716 - acc: 0.1157     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 1.0669 - acc: 0.1322     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 1.0615 - acc: 0.2149     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 1.0567 - acc: 0.2149     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 1.0517 - acc: 0.2231     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 1.0494 - acc: 0.1736     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 1.0446 - acc: 0.1570     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 1.0404 - acc: 0.1488     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 1.0360 - acc: 0.1488     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 1.0344 - acc: 0.1240     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 1.0319 - acc: 0.1240     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 1.0275 - acc: 0.1488     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 1.0242 - acc: 0.2314     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 1.0211 - acc: 0.2893     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 1.0182 - acc: 0.2231     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 1.0147 - acc: 0.2314     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 1.0126 - acc: 0.1901     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 1.0112 - acc: 0.1405     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 1.0088 - acc: 0.1322     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 1.0071 - acc: 0.1157     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 1.0053 - acc: 0.0909     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 1.0014 - acc: 0.1157     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 0.9998 - acc: 0.0909     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 0.9981 - acc: 0.0661     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 0.9941 - acc: 0.1322     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 0.9903 - acc: 0.1570     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e713b00>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with the simplest network likely to do meaningful learning\n",
    "model = Sequential()\n",
    "\n",
    "# Network is (4,3): 4 inputs (4 features), 3 outputs (3 classes)\n",
    "model.add(Dense(3, input_dim=4, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.1827 - acc: 0.3140     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.1687 - acc: 0.3140     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.1631 - acc: 0.3140     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 1.1575 - acc: 0.3140     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 1.1518 - acc: 0.3140     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 1.1487 - acc: 0.3140     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 1.1465 - acc: 0.3140     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 1.1439 - acc: 0.3140     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 1.1396 - acc: 0.3140     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 1.1352 - acc: 0.3140     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 1.1313 - acc: 0.3140     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 1.1275 - acc: 0.3140     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 1.1237 - acc: 0.3140     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 1.1194 - acc: 0.3140     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 1.1139 - acc: 0.3140     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 1.1113 - acc: 0.3140     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 1.1060 - acc: 0.3140     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 1.1018 - acc: 0.3140     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 1.0984 - acc: 0.3388     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 1.0946 - acc: 0.6364     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 1.0929 - acc: 0.6529     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 1.0903 - acc: 0.6529     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 1.0878 - acc: 0.6198     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 1.0856 - acc: 0.5868     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 1.0835 - acc: 0.5372     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 1.0825 - acc: 0.5702     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 1.0800 - acc: 0.4628     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 1.0785 - acc: 0.4050     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 1.0776 - acc: 0.4711     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 1.0754 - acc: 0.3884     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 1.0740 - acc: 0.3719     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 1.0727 - acc: 0.3554     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 1.0712 - acc: 0.3554     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 1.0699 - acc: 0.3554     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 1.0689 - acc: 0.3554     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 1.0678 - acc: 0.3554     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 1.0665 - acc: 0.3554     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 1.0656 - acc: 0.3554     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 1.0647 - acc: 0.3554     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 1.0639 - acc: 0.3554     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 1.0630 - acc: 0.3554     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 1.0618 - acc: 0.3554     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 1.0612 - acc: 0.3554     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 1.0605 - acc: 0.3554     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 1.0594 - acc: 0.3554     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 1.0588 - acc: 0.3554     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 1.0579 - acc: 0.3554     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 1.0571 - acc: 0.3554     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 1.0561 - acc: 0.3554     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 1.0555 - acc: 0.3554     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e9f2e80>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try adding in another layer\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_2.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_2.add(Dense(3, activation='sigmoid'))\n",
    "model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "model_2.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.1246 - acc: 0.3554     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.1240 - acc: 0.3554     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.1233 - acc: 0.3554     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 1.1232 - acc: 0.3554     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 1.1231 - acc: 0.3554     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 1.1223 - acc: 0.3554     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 1.1222 - acc: 0.3554     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 1.1216 - acc: 0.3554     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 1.1210 - acc: 0.3554     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 1.1209 - acc: 0.3554     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 1.1209 - acc: 0.3554     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 1.1206 - acc: 0.3554     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 1.1201 - acc: 0.3554     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 1.1200 - acc: 0.3554     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 1.1198 - acc: 0.3554     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 1.1193 - acc: 0.3554     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 1.1187 - acc: 0.3554     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 1.1181 - acc: 0.3554     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 1.1182 - acc: 0.3554     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 1.1175 - acc: 0.3554     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 1.1174 - acc: 0.3554     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 1.1174 - acc: 0.3554     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 1.1172 - acc: 0.3554     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 1.1171 - acc: 0.3554     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 1.1166 - acc: 0.3554     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 1.1161 - acc: 0.3554     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 1.1156 - acc: 0.3554     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 1.1155 - acc: 0.3554     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 1.1150 - acc: 0.3554     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 1.1146 - acc: 0.3554     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 1.1146 - acc: 0.3554     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 1.1140 - acc: 0.3554     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 1.1137 - acc: 0.3554     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 1.1135 - acc: 0.3554     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 1.1130 - acc: 0.3554     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 1.1126 - acc: 0.3554     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 1.1122 - acc: 0.3554     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 1.1117 - acc: 0.3554     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 1.1117 - acc: 0.3554     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 1.1113 - acc: 0.3554     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 1.1110 - acc: 0.3554     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 1.1105 - acc: 0.3554     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 1.1105 - acc: 0.3554     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 1.1101 - acc: 0.3554     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 1.1101 - acc: 0.3554     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 1.1096 - acc: 0.3554     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 1.1094 - acc: 0.3554     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 1.1090 - acc: 0.3554     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 1.1088 - acc: 0.3554     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 1.1085 - acc: 0.3554     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13f97b048>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "model_3 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_3.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_3.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "model_3.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_3.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.0574 - acc: 0.3554     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.0352 - acc: 0.3554     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.0173 - acc: 0.3554     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 1.0049 - acc: 0.3554     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 0.9832 - acc: 0.3554     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 0.9734 - acc: 0.3554     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 0.9655 - acc: 0.3802     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 0.9549 - acc: 0.3719     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 0.9453 - acc: 0.3802     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 0.9360 - acc: 0.4793     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 0.9279 - acc: 0.5372     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 0.9189 - acc: 0.3636     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 0.9104 - acc: 0.3802     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 0.8994 - acc: 0.6281     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 0.8912 - acc: 0.6694     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 0.8820 - acc: 0.6612     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 0.8751 - acc: 0.6529     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 0.8676 - acc: 0.6694     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 0.8588 - acc: 0.6694     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 0.8502 - acc: 0.6694     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 0.8419 - acc: 0.6694     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 0.8326 - acc: 0.6694     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 0.8240 - acc: 0.6694     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 0.8164 - acc: 0.6694     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 0.8066 - acc: 0.6777     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 0.8005 - acc: 0.6694     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 0.7908 - acc: 0.6694     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 0.7847 - acc: 0.6694     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 0.7755 - acc: 0.6942     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 0.7713 - acc: 0.8017     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 0.7620 - acc: 0.8926     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 0.7545 - acc: 0.6777     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 0.7470 - acc: 0.6777     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 0.7389 - acc: 0.6860     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 0.7300 - acc: 0.6777     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 0.7171 - acc: 0.6942     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 0.7078 - acc: 0.8678     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 0.6993 - acc: 0.9008     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 0.6910 - acc: 0.8926     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 0.6864 - acc: 0.8760     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 0.6775 - acc: 0.7851     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 0.6702 - acc: 0.8347     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 0.6560 - acc: 0.9504     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 0.6493 - acc: 0.7934     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 0.6451 - acc: 0.9174     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 0.6336 - acc: 0.7934     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 0.6270 - acc: 0.9504     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 0.6159 - acc: 0.9339     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 0.6073 - acc: 0.9504     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 0.5983 - acc: 0.8926     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13fd85940>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Values are consistently staying low\n",
    "# Let's try to increase the learning rate\n",
    "model_4 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_4.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_4.add(Dense(3, activation='sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.1)\n",
    "model_4.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_4.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.0947 - acc: 0.4463     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.0931 - acc: 0.3306     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.0914 - acc: 0.3306     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 1.0888 - acc: 0.3306     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 1.0855 - acc: 0.4215     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 1.0821 - acc: 0.3306     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 1.0773 - acc: 0.3884     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 1.0710 - acc: 0.3388     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 1.0636 - acc: 0.6198     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 1.0554 - acc: 0.9008     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 1.0469 - acc: 0.8595     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 1.0372 - acc: 0.8099     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 1.0266 - acc: 0.6446     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 1.0160 - acc: 0.6446     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 1.0033 - acc: 0.6446     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 0.9888 - acc: 0.7521     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 0.9750 - acc: 0.9504     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 0.9611 - acc: 0.9091     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 0.9453 - acc: 0.8264     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 0.9364 - acc: 0.7686     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 0.9262 - acc: 0.7025     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 0.9155 - acc: 0.6694     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 0.9056 - acc: 0.6694     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 0.8942 - acc: 0.7190     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 0.8838 - acc: 0.6777     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 0.8718 - acc: 0.6860     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 0.8603 - acc: 0.6694     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 0.8494 - acc: 0.7521     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 0.8394 - acc: 0.7438     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 0.8280 - acc: 0.6694     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 0.8189 - acc: 0.7273     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 0.8094 - acc: 0.6860     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 0.7991 - acc: 0.7025     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 0.7900 - acc: 0.7934     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 0.7809 - acc: 0.7025     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 0.7711 - acc: 0.6942     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 0.7622 - acc: 0.7190     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 0.7543 - acc: 0.7603     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 0.7463 - acc: 0.8264     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 0.7381 - acc: 0.8843     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 0.7283 - acc: 0.8760     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 0.7199 - acc: 0.7438     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 0.7119 - acc: 0.7438     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 0.7040 - acc: 0.8099     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 0.6972 - acc: 0.7190     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 0.6905 - acc: 0.7851     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 0.6829 - acc: 0.7769     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 0.6766 - acc: 0.7107     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 0.6706 - acc: 0.6860     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 0.6642 - acc: 0.7107     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x144558b38>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Much better! We got into the 90s! \n",
    "# Let's keep the learning rate at 0.1 and see if we can improve more\n",
    "# Weight decay trials\n",
    "\n",
    "# Tried lambda-5,10,20,200 - unable to see improvements\n",
    "# Trying much smaller values helps a little, but not much improvement over no weight decay\n",
    "\n",
    "model_5 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_5.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_5.add(Dense(3, activation='sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.1, decay=1e-6)\n",
    "model_5.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_5.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.0813 - acc: 0.3306     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.0532 - acc: 0.3636     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.0191 - acc: 0.3884     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 0.9596 - acc: 0.5620     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 0.8966 - acc: 0.4298     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 0.7917 - acc: 0.6281     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 0.7053 - acc: 0.6612     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 0.6223 - acc: 0.7273     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 0.5869 - acc: 0.6446     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 0.5086 - acc: 0.7769     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 0.7006 - acc: 0.6446     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 0.5964 - acc: 0.6777     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 0.5619 - acc: 0.7107     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 0.5871 - acc: 0.6860     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 0.5535 - acc: 0.6694     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 0.5827 - acc: 0.7025     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 0.5697 - acc: 0.6529     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 0.5630 - acc: 0.6529     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 0.5940 - acc: 0.6694     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 0.5649 - acc: 0.6694     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 0.5233 - acc: 0.6529     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 0.5288 - acc: 0.6694     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 0.5327 - acc: 0.6694     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 0.5105 - acc: 0.6694     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 0.5142 - acc: 0.6694     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 0.5291 - acc: 0.6694     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 0.5193 - acc: 0.6446     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 0.4517 - acc: 0.7603     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 0.4376 - acc: 0.7769     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 0.5974 - acc: 0.6529     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 0.6589 - acc: 0.6694     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 0.4805 - acc: 0.6777     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 0.3916 - acc: 0.8678     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 0.4444 - acc: 0.7438     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 0.3602 - acc: 0.8760     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 0.3789 - acc: 0.8264     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 0.4101 - acc: 0.7769     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 0.4121 - acc: 0.7769     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 0.3905 - acc: 0.8182     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 0.2522 - acc: 0.9421     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 0.2447 - acc: 0.9339     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 0.1990 - acc: 0.9669     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 0.1749 - acc: 0.9669     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 0.1785 - acc: 0.9587     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 0.1516 - acc: 0.9504     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 0.1402 - acc: 0.9587     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 0.1658 - acc: 0.9669     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 0.1334 - acc: 0.9587     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 0.1416 - acc: 0.9587     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 0.9227 - acc: 0.6694     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146e57dd8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Momentum trials\n",
    "\n",
    "model_6 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_6.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_6.add(Dense(3, activation='sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.1, momentum=0.9)\n",
    "model_6.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_6.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.1355 - acc: 0.3554     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.0882 - acc: 0.3471     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.0960 - acc: 0.3140     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 1.0591 - acc: 0.3140     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 1.0323 - acc: 0.5868     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 0.9385 - acc: 0.6446     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 0.8154 - acc: 0.6116     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 0.6643 - acc: 0.7438     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 0.5611 - acc: 0.7851     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 0.4943 - acc: 0.7190     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 0.4774 - acc: 0.6446     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 0.4130 - acc: 0.8595     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 0.3502 - acc: 0.9504     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 0.3772 - acc: 0.8182     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 0.3714 - acc: 0.8512     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 0.3956 - acc: 0.7769     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 0.2217 - acc: 0.9669     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 0.2712 - acc: 0.9008     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 0.4863 - acc: 0.7851     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 0.7305 - acc: 0.6694     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 0.4869 - acc: 0.7355     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 0.5557 - acc: 0.6446     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 0.5059 - acc: 0.6033     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 0.4914 - acc: 0.6694     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 0.4874 - acc: 0.6694     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 0.4803 - acc: 0.6694     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 0.4802 - acc: 0.6694     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 0.4795 - acc: 0.6694     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 0.4782 - acc: 0.6694     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 0.4798 - acc: 0.6694     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 0.4796 - acc: 0.6612     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 0.4801 - acc: 0.6446     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 0.4797 - acc: 0.6446     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 0.4794 - acc: 0.5950     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 0.4788 - acc: 0.6694     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 0.4785 - acc: 0.6364     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 0.4785 - acc: 0.6364     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 0.4787 - acc: 0.6446     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 0.4785 - acc: 0.6446     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 0.4781 - acc: 0.6364     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 0.4780 - acc: 0.6446     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 0.4781 - acc: 0.6446     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 0.4779 - acc: 0.6446     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 0.4777 - acc: 0.6446     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 0.4772 - acc: 0.6612     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 0.4769 - acc: 0.6694     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 0.4770 - acc: 0.6694     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 0.4767 - acc: 0.6694     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 0.4771 - acc: 0.6694     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 0.4770 - acc: 0.6694     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146fa5f98>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Momentum = 0.9 seems to have helped, what if we increase it?\n",
    "\n",
    "model_7 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_7.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_7.add(Dense(3, activation='sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.1, momentum=0.95)\n",
    "model_7.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_7.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s - loss: 1.1551 - acc: 0.3140     \n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s - loss: 1.0997 - acc: 0.3058     \n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s - loss: 1.0988 - acc: 0.3554     \n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s - loss: 1.0919 - acc: 0.3554     \n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s - loss: 1.0718 - acc: 0.3554     \n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s - loss: 1.0317 - acc: 0.3636     \n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s - loss: 0.9777 - acc: 0.5785     \n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s - loss: 0.9017 - acc: 0.6694     \n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s - loss: 0.8201 - acc: 0.7273     \n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s - loss: 0.7467 - acc: 0.6860     \n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s - loss: 0.6744 - acc: 0.7769     \n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s - loss: 0.6162 - acc: 0.6777     \n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s - loss: 0.5735 - acc: 0.8099     \n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s - loss: 0.5544 - acc: 0.6777     \n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s - loss: 0.5345 - acc: 0.6446     \n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s - loss: 0.5241 - acc: 0.6446     \n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s - loss: 0.4988 - acc: 0.6446     \n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s - loss: 0.4748 - acc: 0.9174     \n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s - loss: 0.4583 - acc: 0.9339     \n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s - loss: 0.4428 - acc: 0.9174     \n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s - loss: 0.4203 - acc: 0.9504     \n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s - loss: 0.4649 - acc: 0.8099     \n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s - loss: 0.4855 - acc: 0.7025     \n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s - loss: 0.3867 - acc: 0.9339     \n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s - loss: 0.3844 - acc: 0.9174     \n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s - loss: 0.5222 - acc: 0.7107     \n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s - loss: 0.4704 - acc: 0.7686     \n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s - loss: 0.4493 - acc: 0.7190     \n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s - loss: 0.4068 - acc: 0.9174     \n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s - loss: 0.5635 - acc: 0.6529     \n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s - loss: 0.5085 - acc: 0.7025     \n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s - loss: 0.4576 - acc: 0.7769     \n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s - loss: 0.3559 - acc: 0.9091     \n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s - loss: 0.3248 - acc: 0.9174     \n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s - loss: 0.3349 - acc: 0.8926     \n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s - loss: 0.3817 - acc: 0.8017     \n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s - loss: 0.3652 - acc: 0.8347     \n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s - loss: 0.4274 - acc: 0.7603     \n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s - loss: 0.3026 - acc: 0.9256     \n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s - loss: 0.2961 - acc: 0.9091     \n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s - loss: 0.3358 - acc: 0.8926     \n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s - loss: 0.2302 - acc: 0.9752     \n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s - loss: 0.2143 - acc: 0.9752     \n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s - loss: 0.2291 - acc: 0.9256     \n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s - loss: 0.1995 - acc: 0.9587     \n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s - loss: 0.1851 - acc: 0.9669     \n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s - loss: 0.1820 - acc: 0.9587     \n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s - loss: 0.1911 - acc: 0.9587     \n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s - loss: 0.2229 - acc: 0.9339     \n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s - loss: 0.1622 - acc: 0.9587     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x144eda278>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not as good...and decreasing to 0.85?\n",
    "model_8 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_8.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_8.add(Dense(3, activation='sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.1, momentum=0.85)\n",
    "model_8.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_8.fit(x_train, y_train, nb_epoch=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 14 samples\n",
      "Epoch 1/100\n",
      "121/121 [==============================] - 0s - loss: 1.1462 - acc: 0.2562 - val_loss: 1.0747 - val_acc: 0.4286\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 0s - loss: 1.1005 - acc: 0.3140 - val_loss: 1.0476 - val_acc: 0.4286\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 0s - loss: 1.0742 - acc: 0.4545 - val_loss: 1.0423 - val_acc: 0.7143\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 0s - loss: 1.0488 - acc: 0.6033 - val_loss: 1.0147 - val_acc: 0.7143\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 0s - loss: 1.0142 - acc: 0.4959 - val_loss: 0.9333 - val_acc: 0.4286\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 0s - loss: 0.9625 - acc: 0.3802 - val_loss: 0.8565 - val_acc: 0.4286\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 0s - loss: 0.9047 - acc: 0.5207 - val_loss: 0.7724 - val_acc: 0.7143\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 0s - loss: 0.8121 - acc: 0.6694 - val_loss: 0.6782 - val_acc: 0.7143\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 0s - loss: 0.7284 - acc: 0.6694 - val_loss: 0.5990 - val_acc: 0.7143\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 0s - loss: 0.6519 - acc: 0.6777 - val_loss: 0.5562 - val_acc: 0.7143\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 0s - loss: 0.5979 - acc: 0.6364 - val_loss: 0.5171 - val_acc: 0.7143\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 0s - loss: 0.5904 - acc: 0.6694 - val_loss: 0.4957 - val_acc: 0.7143\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 0s - loss: 0.5491 - acc: 0.7769 - val_loss: 0.4838 - val_acc: 0.7143\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 0s - loss: 0.5573 - acc: 0.6446 - val_loss: 0.4781 - val_acc: 0.7143\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 0s - loss: 0.5511 - acc: 0.6446 - val_loss: 0.4491 - val_acc: 0.7143\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 0s - loss: 0.5149 - acc: 0.7025 - val_loss: 0.4457 - val_acc: 0.7143\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 0s - loss: 0.5102 - acc: 0.6860 - val_loss: 0.4265 - val_acc: 0.7143\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 0s - loss: 0.5176 - acc: 0.6694 - val_loss: 0.4268 - val_acc: 0.7143\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 0s - loss: 0.4795 - acc: 0.7521 - val_loss: 0.4449 - val_acc: 0.7143\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 0s - loss: 0.5121 - acc: 0.6446 - val_loss: 0.4222 - val_acc: 0.7143\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 0s - loss: 0.4850 - acc: 0.6446 - val_loss: 0.4178 - val_acc: 0.7143\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 0s - loss: 0.4701 - acc: 0.7190 - val_loss: 0.3815 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 0s - loss: 0.4442 - acc: 0.9421 - val_loss: 0.3767 - val_acc: 0.7857\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 0s - loss: 0.5013 - acc: 0.6860 - val_loss: 0.3482 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 0s - loss: 0.4086 - acc: 0.9504 - val_loss: 0.3751 - val_acc: 0.7857\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 0s - loss: 0.4187 - acc: 0.7934 - val_loss: 0.4158 - val_acc: 0.7143\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 0s - loss: 0.4860 - acc: 0.6777 - val_loss: 0.3681 - val_acc: 0.8571\n",
      "Epoch 28/100\n",
      "121/121 [==============================] - 0s - loss: 0.4442 - acc: 0.8099 - val_loss: 0.3767 - val_acc: 0.7143\n",
      "Epoch 29/100\n",
      "121/121 [==============================] - 0s - loss: 0.4549 - acc: 0.7025 - val_loss: 0.3705 - val_acc: 0.7857\n",
      "Epoch 30/100\n",
      "121/121 [==============================] - 0s - loss: 0.3797 - acc: 0.8678 - val_loss: 0.3171 - val_acc: 0.8571\n",
      "Epoch 31/100\n",
      "121/121 [==============================] - 0s - loss: 0.3554 - acc: 0.9008 - val_loss: 0.3395 - val_acc: 0.7857\n",
      "Epoch 32/100\n",
      "121/121 [==============================] - 0s - loss: 0.3684 - acc: 0.8430 - val_loss: 0.2520 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "121/121 [==============================] - 0s - loss: 0.3438 - acc: 0.8678 - val_loss: 0.4474 - val_acc: 0.7857\n",
      "Epoch 34/100\n",
      "121/121 [==============================] - 0s - loss: 0.3917 - acc: 0.7851 - val_loss: 0.3376 - val_acc: 0.7857\n",
      "Epoch 35/100\n",
      "121/121 [==============================] - 0s - loss: 0.3012 - acc: 0.9091 - val_loss: 0.4760 - val_acc: 0.7143\n",
      "Epoch 36/100\n",
      "121/121 [==============================] - 0s - loss: 0.6452 - acc: 0.6777 - val_loss: 0.5413 - val_acc: 0.7143\n",
      "Epoch 37/100\n",
      "121/121 [==============================] - 0s - loss: 0.5891 - acc: 0.6281 - val_loss: 0.4352 - val_acc: 0.7143\n",
      "Epoch 38/100\n",
      "121/121 [==============================] - 0s - loss: 0.5007 - acc: 0.6612 - val_loss: 0.4292 - val_acc: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1469c3668>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This looks good, and we didn't see the dip back down to ~.6 at epoch 50\n",
    "\n",
    "# So far we have:\n",
    "# momentum: 0.85\n",
    "# learning rate: 0.1\n",
    "# network is (4,4,3) fully connected sigmoid units\n",
    "\n",
    "# How about early stopping?\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model_9 = Sequential()\n",
    "\n",
    "# Network is (4,4,3): 4 inputs, 4 hidden neurons, 3 outputs\n",
    "model_9.add(Dense(4, input_dim=4, activation='sigmoid'))\n",
    "model_9.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.1, momentum=0.85)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model_9.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_9.fit(x_train, y_train, nb_epoch=100, batch_size=20, callbacks=[early_stopping], validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
